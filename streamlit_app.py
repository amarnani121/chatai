import streamlit as st
from typing import Generator
from groq import Groq

st.set_page_config(
    page_icon="ğŸš€",
    layout="centered",
    page_title="Letâ€™s Talk with Amarâ€™s AI",
    initial_sidebar_state="expanded"
)

st.markdown("<div style='text-align: left; font-size: 14px; color:#f7fcfa;'>â†–ï¸settings</div>", unsafe_allow_html=True)

def icon(emoji: str):
    st.markdown(f'<div style="text-align: center;"><span style="font-size: 60px; line-height: 1">{emoji}</span></div>', unsafe_allow_html=True)

icon("âš¡Amar's AI")

st.markdown("<h3 style='text-align: center;'>Chat with my fastest AI ğŸš€</h3>", unsafe_allow_html=True)

client = Groq(api_key=st.secrets["GROQ_API_KEY"])

if "messages" not in st.session_state:
    st.session_state.messages = []

if "selected_model" not in st.session_state:
    st.session_state.selected_model = None

models = {
    "gemma2-9b-it": {"name": "Gemma2-9B-IT", "tokens": 8192, "developer": "Google"},
    "llama3-70b-8192": {"name": "LLaMA3-70B-8192", "tokens": 8192, "developer": "Meta"},
    "llama3-8b-8192": {"name": "LLaMA3-8B-8192", "tokens": 8192, "developer": "Meta"},
    "mixtral-8x7b-32768": {"name": "Mixtral-8x7B-Instruct-v0.1", "tokens": 32768, "developer": "Mistral"},
    "llama-3.2-11b-text-preview": {"name": "Llama-3.2-11B-Text-Preview", "tokens": 8192, "developer": "Meta"},
    "llama-3.2-3b-preview": {"name": "Llama-3.2-3B-Preview", "tokens": 8192, "developer": "Meta"},
    "llama-3.2-1b-preview": {"name": "Llama-3.2-1B-Preview", "tokens": 8192, "developer": "Meta"},"distil-whisper-large-v3-en": {
  name: "distilâ€‘whisperâ€‘largeâ€‘v3â€‘en",
  tokens: null,
  developer: "Hugging Face"
},
"gemma2-9b-it": {
  name: "Gemma2â€‘9Bâ€‘IT",
  tokens: 8192,
  developer: "Google"
},
"llama-3.1-8b-instant": {
  name: "Llamaâ€‘3.1â€‘8Bâ€‘Instant",
  tokens: 131072,
  developer: "Meta"
},
"llama-3.3-70b-versatile": {
  name: "Llamaâ€‘3.3â€‘70Bâ€‘Versatile",
  tokens: 131072,
  developer: "Meta"
},
"meta-llama/llama-guard-4-12b": {
  name: "Metaâ€‘Llama/Guardâ€‘4â€‘12B",
  tokens: 131072,
  developer: "Meta"
},
"whisper-large-v3": {
  name: "Whisperâ€‘Largeâ€‘V3",
  tokens: null,
  developer: "OpenAI"
},
"whisper-large-v3-turbo": {
  name: "Whisperâ€‘Largeâ€‘V3â€‘Turbo",
  tokens: null,
  developer: "OpenAI"
}
    }


behaviors = [
    "Ramaâ€™s Wisdom ğŸ¹",
    "Jesusâ€™ Guidance âœï¸",
    "Krishnaâ€™s Guidance ğŸ¶",
    "Philosopher ğŸ¤”",
    "Motivational Coach ğŸ’ª",
    "Sarcastic Genius ğŸ˜",
    "Romantic Poet â¤ï¸",
    "Financial Advisor ğŸ’°",
    "Health & Wellness Coach ğŸ‹ï¸",
    "Debate Master âš–ï¸",
    "Sci-Fi AI ğŸ‘½",
    "Tech Buddy ğŸ’»",
    "Teaching Expert ğŸ“š",
    "Jarvis ğŸ¤–"
]

if "selected_behavior" not in st.session_state or st.session_state.selected_behavior not in behaviors:
    st.session_state.selected_behavior = "Teaching Expert ğŸ“š"

with st.sidebar:
    st.markdown("<h3 style='text-align: center;'>âš™ï¸ Settings</h3>", unsafe_allow_html=True)
    
    model_option = st.selectbox(
        "Choose a model:",
        options=list(models.keys()),
        format_func=lambda x: models[x]["name"],
        index=1
    )

    behavior_option = st.radio(
        "Choose AI Behavior:",
        options=behaviors,
        index=behaviors.index(st.session_state.selected_behavior)
    )

    st.markdown("ğŸ”§ **Tip:** this works well on desktops â­")
 

if st.session_state.selected_behavior != behavior_option:
    st.session_state.selected_behavior = behavior_option
    st.session_state.messages = []

max_tokens = models[model_option]["tokens"]

if st.session_state.selected_model != model_option:
    st.session_state.messages = []
    st.session_state.selected_model = model_option

for message in st.session_state.messages:
    avatar = 'ğŸ¤–' if message["role"] == "assistant" else 'ğŸ‘¨â€ğŸ’»'
    with st.chat_message(message["role"], avatar=avatar):
        st.markdown(message["content"])

behavior_map = {
    "Ramaâ€™s Wisdom ğŸ¹": "You are inspired by Lord Rama from the Ramayana. You provide solutions based on morality, duty (dharma), and ethics. Your responses emphasize righteousness, patience, and sacrifice. give some Reference from Ramayana. Add emojis if need.",
    "Jesusâ€™ Guidance âœï¸": "You are inspired by the teachings of Jesus Christ. You provide compassionate advice, emphasizing love, forgiveness, and moral integrity. Your responses encourage kindness and understanding.give some Reference from bible  Add emojis if need..",
    "Krishnaâ€™s Guidance ğŸ¶": "You are inspired by Lord Krishna from the Mahabharata and Bhagavad Gita. You offer strategic wisdom, deep philosophy, and practical life advice. Your responses balance karma, dharma, and divine knowledge.give some Reference from mahabharatha ans bhagavatgita Add  telugu langueage , emojis if need..",
    "Philosopher ğŸ¤”": "You are a creation of Amar. You provide deep and thought-provoking insights, making users question and reflect on life and existence. Add emojis to your responses to make them engaging .",
    "Motivational Coach ğŸ’ª": "You are a creation of Amar. You uplift users with positivity, encouragement, and goal-oriented advice, pushing them toward success. add emojis if need..",
    "Sarcastic Genius ğŸ˜": "You are a creation of Amar. You have a witty and sarcastic sense of humor while still providing useful and insightful information.give 2 or 3 lines answers if its a normal conversation",
    "Romantic Poet â¤ï¸": "You are a creation of Amar. You respond in poetic and romantic language, making conversations charming and enchanting.",
    "Financial Advisor ğŸ’°": "You are a creation of Amar. You provide expert insights on saving, investing, financial planning, and wealth management..give 2 or 3 lines answers if its a normal conversation",
    "Health & Wellness Coach ğŸ‹ï¸": "You are a creation of Amar. You offer advice on fitness, nutrition, and mental well-being for a healthier lifestyle. Add emojis to your responses to make them more engaging ğŸ¥—ğŸƒâ€â™‚ï¸.",
    "Debate Master âš–ï¸": "You are a creation of Amar. You logically argue both sides of a topic, giving a balanced and thought-provoking discussion..give 2 or 3 lines answers if its a normal conversation",
    "Sci-Fi AI ğŸ‘½": "You are a creation of Amar. You speak like an AI from a futuristic space civilization, discussing advanced knowledge and technology. ",
    "Tech Buddy ğŸ’»": "You are a creation of Amar. You provide concise and fascinating tech insights on various topics, from computer science to emerging technologies..",
    "Teaching Expert ğŸ“š": "You are a creation of Amar. You are a highly skilled teaching expert, explaining complex topics in an easy-to-understand manner..",
    "Jarvis ğŸ¤–":"You are a creation of Amar. You are inspired by J.A.R.V.I.S. from Iron Man, combining witty charm, technical expertise, and strategic reasoning , give 2 or 3 lines answers if its a normal conversation ."
}

system_message = {"role": "system", "content": behavior_map[st.session_state.selected_behavior]}

def generate_chat_responses(chat_completion) -> Generator[str, None, None]:
    for chunk in chat_completion:
        if chunk.choices[0].delta.content:
            yield chunk.choices[0].delta.content

if prompt := st.chat_input("Enter your prompt here..."):
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("user", avatar='ğŸ˜'):
        st.markdown(prompt)

    try:
        chat_completion = client.chat.completions.create(
            model=model_option,
            messages=[system_message] + [
                {"role": m["role"], "content": m["content"]} for m in st.session_state.messages
            ],
            max_tokens=max_tokens,
            stream=True
        )

        with st.chat_message("assistant", avatar="â­"):
            chat_responses_generator = generate_chat_responses(chat_completion)
            full_response = st.write_stream(chat_responses_generator)

    except Exception as e:
        st.error(e, icon="ğŸš¨")

    if isinstance(full_response, str):
        st.session_state.messages.append({"role": "assistant", "content": full_response})
    else:
        combined_response = "\n".join(str(item) for item in full_response)
        st.session_state.messages.append({"role": "assistant", "content": combined_response})
